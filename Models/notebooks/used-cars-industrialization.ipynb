{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8219a6ac",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa589c46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:45.536534Z",
     "start_time": "2022-05-16T15:37:35.164176Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import joblib\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import norm, skew\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44c24fd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:45.573079Z",
     "start_time": "2022-05-16T15:37:45.545612Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_mae(y_test: np.ndarray, y_pred: np.ndarray, precision: int = 2):\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    return {'mae': f\"{round(mae, precision)}\"}\n",
    "\n",
    "def save_object(obj, filename):\n",
    "    current_working_dir = os.path.abspath(os.getcwd())\n",
    "    file_path = os.path.join(current_working_dir, 'models', filename)\n",
    "    joblib.dump(obj, file_path)\n",
    "    \n",
    "def load_object(filename):\n",
    "    current_working_dir = os.path.abspath(os.getcwd())\n",
    "    file_path = os.path.join(current_working_dir, 'models', filename)\n",
    "    obj = joblib.load(file_path)\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8256b05e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:45.705056Z",
     "start_time": "2022-05-16T15:37:45.583163Z"
    }
   },
   "outputs": [],
   "source": [
    "selected_features = ['powerPS', 'vehicleType', 'brand', 'fuelType', 'kilometer', 'price']\n",
    "selected_predictors = ['powerPS', 'vehicleType', 'brand', 'fuelType', 'kilometer']\n",
    "continuous_features = ['powerPS', 'kilometer', 'price']\n",
    "continuous_predictors = ['powerPS', 'kilometer']\n",
    "categorical_features = ['vehicleType', 'brand', 'fuelType']\n",
    "target_feature = 'price'\n",
    "\n",
    "imputer_filename = 'imputer.joblib'\n",
    "pipeline_filename = 'pipeline.joblib'\n",
    "skewed_predictors = 'skewed_predictors.joblib'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ede0a33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:45.795802Z",
     "start_time": "2022-05-16T15:37:45.707718Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_data_type(data):\n",
    "    fixed_data = data.astype({\n",
    "        'powerPS': object\n",
    "    })\n",
    "    return fixed_data\n",
    "\n",
    "def update_data_features(data_raw, features):\n",
    "    return data_raw[features]\n",
    "\n",
    "def clean_data(data_raw):\n",
    "    updated_data_raw = update_data_features(data_raw, selected_features)\n",
    "    fixed_type_data_raw = fix_data_type(updated_data_raw)\n",
    "    return fixed_type_data_raw\n",
    "\n",
    "def clean_inference_data(data):\n",
    "    updated_data_raw = update_data_features(data, selected_predictors)\n",
    "    fixed_type_data_raw = fix_data_type(updated_data_raw)\n",
    "    return fixed_type_data_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58f8f22a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:45.964217Z",
     "start_time": "2022-05-16T15:37:45.799561Z"
    }
   },
   "outputs": [],
   "source": [
    "def fix_data(data):\n",
    "    data.drop_duplicates(inplace=True)\n",
    "    data.drop(data[data['powerPS'] == 0].index, inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0189fb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:46.037467Z",
     "start_time": "2022-05-16T15:37:45.967388Z"
    }
   },
   "outputs": [],
   "source": [
    "def handing_missing_values(data):\n",
    "    si = SimpleImputer(strategy='constant', fill_value='any')\n",
    "    si.fit(data[selected_predictors])\n",
    "    save_object(si, imputer_filename)\n",
    "\n",
    "def fix_missing_values(data):\n",
    "    si = load_object(imputer_filename)\n",
    "    data.loc[:, selected_predictors] = si.transform(data[selected_predictors])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14ae2a80",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:46.121322Z",
     "start_time": "2022-05-16T15:37:46.039548Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_skewed_predictors(data):\n",
    "    skewness = data[continuous_predictors].apply(lambda x: skew(x))\n",
    "    skewness = skewness[abs(skewness) > 0.5]\n",
    "    skewed_features = skewness.index\n",
    "    save_object(skewed_features, skewed_predictors)\n",
    "\n",
    "def fix_predictor_skewness(data):\n",
    "    skewed_features = load_object(skewed_predictors)\n",
    "    data[skewed_features] = np.log1p(data[skewed_features].astype(float))\n",
    "    return data\n",
    "\n",
    "def fix_target_skewness(data):\n",
    "    data[target_feature] = np.log1p(data[target_feature].astype(float))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0c3f274",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:46.205916Z",
     "start_time": "2022-05-16T15:37:46.136341Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess_for_build(data):\n",
    "    fixed_data = fix_data(data)\n",
    "    handing_missing_values(fixed_data)\n",
    "    no_missing_array = fix_missing_values(fixed_data)\n",
    "    no_missing_data = pd.DataFrame(no_missing_array, columns=selected_features)\n",
    "    find_skewed_predictors(no_missing_data)\n",
    "    unskewed_predictors_data = fix_predictor_skewness(no_missing_data)\n",
    "    unskewed_data = fix_target_skewness(unskewed_predictors_data)\n",
    "    return unskewed_data\n",
    "\n",
    "def preprocess_for_prediction(data):\n",
    "    no_missing_data = fix_missing_values(data)\n",
    "    unskewed_data = fix_predictor_skewness(no_missing_data)\n",
    "    return unskewed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9933ceb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:46.387169Z",
     "start_time": "2022-05-16T15:37:46.212551Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_train_data_raw(data, target_feature):\n",
    "    X = data.drop(target_feature, axis=1)\n",
    "    y = data[target_feature]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.25, random_state = 0)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86c59a22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:46.540042Z",
     "start_time": "2022-05-16T15:37:46.390640Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_pipeline():\n",
    "    categorical_transformer = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    numeric_transformer = StandardScaler()\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"cat\", categorical_transformer, categorical_features),\n",
    "            (\"num\", numeric_transformer, continuous_predictors),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    pipe = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', RandomForestRegressor(n_estimators=50, max_depth=10, max_features=\"sqrt\"))\n",
    "    ])\n",
    "    return pipe\n",
    "    \n",
    "def train_model(X, y):\n",
    "    # Train\n",
    "    pipeline = build_pipeline()\n",
    "    pipeline.fit(X, y)\n",
    "    save_object(pipeline, pipeline_filename)\n",
    "    \n",
    "def predict(data):\n",
    "    pipeline = load_object(pipeline_filename)\n",
    "    y_pred = pipeline.predict(data)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cc717e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:37:46.648140Z",
     "start_time": "2022-05-16T15:37:46.544582Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_model(data_raw: pd.DataFrame):\n",
    "    cleaned_data = clean_data(data_raw)\n",
    "    preprocessed_data = preprocess_for_build(cleaned_data)\n",
    "    X_train, X_val, y_train, y_val = split_train_data_raw(preprocessed_data, target_feature)\n",
    "    # Train model and predict\n",
    "    train_model(X_train, y_train)\n",
    "    y_pred = predict(X_val)\n",
    "    result = mean_absolute_error(y_val, y_pred)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40664dcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:40:37.955543Z",
     "start_time": "2022-05-16T15:40:24.668437Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7708193113907246"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw = pd.read_csv('./data/autos.csv', encoding='ISO-8859-1')\n",
    "build_model(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "44de6615",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T21:55:44.506576Z",
     "start_time": "2022-05-09T21:43:59.978727Z"
    }
   },
   "outputs": [],
   "source": [
    "raw = pd.read_csv('./data/autos.csv', encoding='ISO-8859-1')\n",
    "cleaned_data = clean_data(raw)\n",
    "preprocessed_data = preprocess_for_build(cleaned_data)\n",
    "preprocessed_data.sample(n=5)\n",
    "X_train, X_val, y_train, y_val = split_train_data_raw(preprocessed_data, target_feature)\n",
    "# Train model and predict\n",
    "train_model(X_train, y_train)\n",
    "y_pred = predict(X_val)\n",
    "result = mean_absolute_error(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "698461fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-09T22:08:54.018336Z",
     "start_time": "2022-05-09T22:08:53.969600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6665314754939098"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ac56349",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a9b0954",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-16T15:38:58.617929Z",
     "start_time": "2022-05-16T15:38:56.759105Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "118",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexpm1(y_pred)\n\u001b[1;32m      8\u001b[0m data_raw \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data/test.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmake_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_raw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m y_pred\n",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36mmake_predictions\u001b[0;34m(input_data_raw)\u001b[0m\n\u001b[1;32m      3\u001b[0m data \u001b[38;5;241m=\u001b[39m clean_inference_data(input_data_raw)\n\u001b[1;32m      4\u001b[0m preprocessed_data \u001b[38;5;241m=\u001b[39m preprocess_for_prediction(data)\n\u001b[0;32m----> 5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexpm1(y_pred)\n",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(data):\n\u001b[0;32m---> 25\u001b[0m     pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mload_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline_filename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     y_pred \u001b[38;5;241m=\u001b[39m pipeline\u001b[38;5;241m.\u001b[39mpredict(data)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m y_pred\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mload_object\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     11\u001b[0m current_working_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mabspath(os\u001b[38;5;241m.\u001b[39mgetcwd())\n\u001b[1;32m     12\u001b[0m file_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(current_working_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m, filename)\n\u001b[0;32m---> 13\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[43mjoblib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/numpy_pickle.py:587\u001b[0m, in \u001b[0;36mload\u001b[0;34m(filename, mmap_mode)\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(fobj, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    582\u001b[0m                 \u001b[38;5;66;03m# if the returned file object is a string, this means we\u001b[39;00m\n\u001b[1;32m    583\u001b[0m                 \u001b[38;5;66;03m# try to load a pickle file generated with an version of\u001b[39;00m\n\u001b[1;32m    584\u001b[0m                 \u001b[38;5;66;03m# Joblib so we load it with joblib compatibility function.\u001b[39;00m\n\u001b[1;32m    585\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m load_compatibility(fobj)\n\u001b[0;32m--> 587\u001b[0m             obj \u001b[38;5;241m=\u001b[39m \u001b[43m_unpickle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmmap_mode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/joblib/numpy_pickle.py:506\u001b[0m, in \u001b[0;36m_unpickle\u001b[0;34m(fobj, filename, mmap_mode)\u001b[0m\n\u001b[1;32m    504\u001b[0m obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    505\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 506\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[43munpickler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    507\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m unpickler\u001b[38;5;241m.\u001b[39mcompat_mode:\n\u001b[1;32m    508\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe file \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has been generated with a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    509\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjoblib version less than 0.10. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    510\u001b[0m                       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease regenerate this pickle file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    511\u001b[0m                       \u001b[38;5;241m%\u001b[39m filename,\n\u001b[1;32m    512\u001b[0m                       \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/pickle.py:1212\u001b[0m, in \u001b[0;36m_Unpickler.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEOFError\u001b[39;00m\n\u001b[1;32m   1211\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, bytes_types)\n\u001b[0;32m-> 1212\u001b[0m         \u001b[43mdispatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   1213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _Stop \u001b[38;5;28;01mas\u001b[39;00m stopinst:\n\u001b[1;32m   1214\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stopinst\u001b[38;5;241m.\u001b[39mvalue\n",
      "\u001b[0;31mKeyError\u001b[0m: 118"
     ]
    }
   ],
   "source": [
    "def make_predictions(input_data_raw: pd.DataFrame):\n",
    "    # the model and all the data preparation objects (encoder, etc) should be loaded from the models folder\n",
    "    data = clean_inference_data(input_data_raw)\n",
    "    preprocessed_data = preprocess_for_prediction(data)\n",
    "    y_pred = predict(preprocessed_data)\n",
    "    return np.expm1(y_pred)\n",
    "\n",
    "data_raw = pd.read_csv('./data/test.csv')\n",
    "y_pred = make_predictions(data_raw)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e1534",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
